{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc600209-4305-44e3-b0f0-611b61a0bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaed5316-d658-4872-8089-4bd363c0274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bpeTokenizer():\n",
    "    def __init__(self, encoding = \"gpt2\"):\n",
    "        # initialize encoder\n",
    "        self.encoding = tiktoken.get_encoding(encoding)\n",
    "        self.raw_text = \"\"\n",
    "\n",
    "    def encode(self, text):\n",
    "        if isinstance(text, str):\n",
    "            return self.encoding.encode(text)\n",
    "        elif isinstance(text, list):\n",
    "            tokens = []\n",
    "            for word in text:\n",
    "                tokens += self.encoding.encode(word)\n",
    "            return tokens\n",
    "        else:\n",
    "            raise TypeError(\"Input must be str or list of str\")\n",
    "\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        if isinstance(tokens, int):\n",
    "            return self.encoding.decode([tokens])   # single token\n",
    "        elif isinstance(tokens, list):\n",
    "            return self.encoding.decode(tokens)     # full list\n",
    "        else:\n",
    "            raise TypeError(\"tokens must be int or list of ints\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd9bb1-7449-48a0-be63-64ccfcd4d51b",
   "metadata": {},
   "source": [
    "# Testing the tokenizer \n",
    "### Creting an instance of the bpe tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7eca96-ad1c-448a-aa79-9823c459ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = bpeTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc9e7eb-34cb-47a9-a728-d55a9b004fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8727, 533, 36981, 257, 591, 73, 7568, 74]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"whoareYOU aksjdfk\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b7c1a7-d6f3-4aeb-8112-7440a372c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whoareYOU aksjdfk'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73120e2c-e30b-40ae-86c3-19537c96ffa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
